gpu_memory_utilization = 0.95

[model]
# name = "/home/htkumar/nano_rl/outputs/weights/step_100"
max_model_len = 2048
enforce_eager = false

# [parallel]
# tp = 2 # split model across GPUs.
